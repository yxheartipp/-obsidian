---
alias: []
Type: 
tags: ["#review"]
sr-due: 2024-09-15
sr-interval: 1
sr-ease: 250
---

例如，微调 GPT3 将需要超过 8 个具有 3D 并行性的 DGX-2 节点（128 个 GPU），以仅适合训练模型，即使单个 DGX-2 节点（16-GPU）有足够的计算以合理的时间对其进行微调。

在本文中，我们从 3D 并行性向前迈进，并提出了 ZeRO-Infinity，这是一个能够解决上述所有大型模型训练挑战的新系统

这允许 ZeRO-Infinity 同时利用 CPU 和 NVMe 内存来支持有限 GPU 资源的大规模模型大小。此外，ZeRO-Infinity 还引入了一种新的 GPU 内存优化技术，称为以内存为中心的平铺，以支持非常大的单个层，否则即使一次一层，也不会适合 GPU 内存。随着无限卸载引擎和以内存为中心的平铺，ZeRO-Infinity不仅支持模型大小的下一个1000倍增长，而且使得GPU资源有限的数据科学家可以访问大型模型。

ZeRO-Infinity引入了一种新的数据分区策略，利用所有设备上的聚合内存带宽，我们称之为带宽中心分区，并将其与强大的通信重叠中心设计相结合，以及在无穷卸载引擎中实现高性能NVMe访问的优化。总之，ZeRO-Infinity 提供了出色的训练效率，尽管将数据卸载到 CPU 或 NVMe，但不受其有限带宽的影响。

ZeRO-Infinity 消除了手动模型代码重构的需要，即使通过易于启发的实现扩展到数万亿的参数，该实现自动化训练任意模型架构所需的所有通信和数据分区。

ZeRO-Infinity(第5、6节和第7节):一种新颖的DL训练系统技术，包括五种创新技术，以解决内存和带宽需求，以提供前所未有的模型规模，这是可访问的，易于使用，同时实现出色的训练效率:
i)无限卸载引擎，通过同时利用GPU、CPU和NVMe内存以及GPU和CPU计算，充分利用现代集群上的异构架构，
ii)以内存为中心的平铺来处理大量操作符，而不需要模型并行性，
iii)带宽为中心的分区，以利用所有并行设备上的聚合内存带宽，
iv)重叠中心设计，
v)易于启发的实现，以避免模型代码重构。


ZeRO-Infinity 设计了一种强大的卸载机制，称为无穷大卸载引擎，该机制可以将所有分区的模型状态卸载到 CPU 或 NVMe 内存，或者根据内存需求将它们保留在 GPU 上。

![[Pasted image 20240914141023.png]]

因此，通过将激活检查点卸载到 CPU 内存，ZeRO-Infinity 可以拟合具有数百万亿个参数的模型的激活检查点。

实际上，这极具挑战性，因为 CPU 内存比 GPU 内存带宽慢一个数量级，而 NVMe 带宽但比 CPU 内存带宽慢一个数量级。此外，从 GPU 读取和写入这些内存甚至更慢（见图 2b）。

这提出了两个问题：i) 对于大型模型，即使在 CPU 内存中，激活内存也会变得太大而无法拟合，并且 ii) 当扩展到数百或数千个 GPU 以实现有效收敛时，有效的批量大小变得太大。